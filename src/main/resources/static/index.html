<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hidaya Voice AI - Quran Recitation Recognition</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            color: #333;
        }

        .container {
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            padding: 3rem;
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.1);
            text-align: center;
            max-width: 600px;
            width: 90%;
            position: relative;
            overflow: hidden;
        }

        .container::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            height: 4px;
            background: linear-gradient(90deg, #667eea, #764ba2);
        }

        h1 {
            color: #2c3e50;
            margin-bottom: 1rem;
            font-size: 2.5rem;
            font-weight: 700;
        }

        .subtitle {
            color: #7f8c8d;
            margin-bottom: 2rem;
            font-size: 1.1rem;
            line-height: 1.6;
        }

        .microphone-section {
            margin: 2rem 0;
        }

        .mic-button {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            border: none;
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: white;
            font-size: 3rem;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 10px 30px rgba(102, 126, 234, 0.3);
            position: relative;
            overflow: hidden;
        }

        .mic-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 15px 40px rgba(102, 126, 234, 0.4);
        }

        .mic-button:active {
            transform: translateY(0);
        }

        .mic-button.recording {
            background: linear-gradient(135deg, #e74c3c, #c0392b);
            animation: pulse 1.5s infinite;
        }

        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.05); }
            100% { transform: scale(1); }
        }

        .mic-button.recording::after {
            content: '';
            position: absolute;
            top: -10px;
            left: -10px;
            right: -10px;
            bottom: -10px;
            border: 2px solid #e74c3c;
            border-radius: 50%;
            animation: ripple 1.5s infinite;
        }

        @keyframes ripple {
            0% { transform: scale(1); opacity: 1; }
            100% { transform: scale(1.3); opacity: 0; }
        }

        .status {
            margin: 1rem 0;
            padding: 1rem;
            border-radius: 10px;
            font-weight: 500;
            min-height: 60px;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .status.idle {
            background: #ecf0f1;
            color: #7f8c8d;
        }

        .status.listening {
            background: #e8f5e8;
            color: #27ae60;
        }

        .status.processing {
            background: #fff3cd;
            color: #856404;
        }

        .status.error {
            background: #f8d7da;
            color: #721c24;
        }

        .transcript {
            background: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 10px;
            padding: 1rem;
            margin: 1rem 0;
            min-height: 80px;
            text-align: left;
            font-size: 1rem;
            line-height: 1.5;
        }

        .result {
            background: #d4edda;
            border: 1px solid #c3e6cb;
            border-radius: 10px;
            padding: 1rem;
            margin: 1rem 0;
            color: #155724;
            font-weight: 600;
        }

        .features {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 1rem;
            margin: 2rem 0;
        }

        .feature {
            background: #f8f9fa;
            padding: 1.5rem;
            border-radius: 10px;
            border-left: 4px solid #667eea;
        }

        .feature h3 {
            color: #2c3e50;
            margin-bottom: 0.5rem;
        }

        .feature p {
            color: #7f8c8d;
            font-size: 0.9rem;
        }

        .loading {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid #f3f3f3;
            border-top: 3px solid #667eea;
            border-radius: 50%;
            animation: spin 1s linear infinite;
            margin-right: 10px;
        }

        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        @media (max-width: 768px) {
            .container {
                padding: 2rem;
                margin: 1rem;
            }

            h1 {
                font-size: 2rem;
            }

            .mic-button {
                width: 100px;
                height: 100px;
                font-size: 2.5rem;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üéôÔ∏è Hidaya Voice AI</h1>
        <p class="subtitle">
            Recite Quranic verses and get instant recognition. 
            Our AI-powered system identifies Surah and Ayah numbers from your recitation.
        </p>

        <div class="microphone-section">
            <button class="mic-button" id="micButton" title="Click to start recording">
                üé§
            </button>
            
            <div class="status idle" id="status">
                Click the microphone to start recording
            </div>

            <div class="transcript" id="transcript" style="display: none;">
                <strong>Your recitation:</strong><br>
                <span id="transcriptText"></span>
            </div>

            <div class="result" id="result" style="display: none;">
                <strong>Recognition Result:</strong><br>
                <span id="resultText"></span>
            </div>
        </div>

        <div class="features">
            <div class="feature">
                <h3>üéØ Accurate Recognition</h3>
                <p>Advanced fingerprinting technology for precise Quranic verse identification</p>
            </div>
            <div class="feature">
                <h3>‚ö° Real-time Processing</h3>
                <p>Instant results as you recite with minimal latency</p>
            </div>
            <div class="feature">
                <h3>üì± Easy to Use</h3>
                <p>Simple one-click recording interface for seamless experience</p>
            </div>
        </div>
    </div>

    <script>
        class VoiceRecognition {
            constructor() {
                this.recognition = null;
                this.mediaRecorder = null;
                this.audioChunks = [];
                this.isRecording = false;
                this.initializeSpeechRecognition();
                this.bindEvents();
            }

            initializeSpeechRecognition() {
                if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
                    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                    this.recognition = new SpeechRecognition();
                    
                    this.recognition.continuous = true;
                    this.recognition.interimResults = true;
                    this.recognition.lang = 'ar-SA'; // Arabic language
                    
                    this.recognition.onstart = () => {
                        this.isRecording = true;
                        this.updateUI('listening', 'Listening to your recitation...');
                        this.showTranscript();
                    };
                    
                    this.recognition.onresult = (event) => {
                        let finalTranscript = '';
                        let interimTranscript = '';
                        
                        for (let i = event.resultIndex; i < event.results.length; i++) {
                            const transcript = event.results[i][0].transcript;
                            if (event.results[i].isFinal) {
                                finalTranscript += transcript;
                            } else {
                                interimTranscript += transcript;
                            }
                        }
                        
                        this.updateTranscript(finalTranscript, interimTranscript);
                    };
                    
                    this.recognition.onerror = (event) => {
                        console.error('Speech recognition error:', event.error);
                        this.updateUI('error', `Error: ${event.error}`);
                        this.stopRecording();
                    };
                    
                    this.recognition.onend = () => {
                        this.isRecording = false;
                        this.updateUI('idle', 'Click the microphone to start recording');
                        this.hideTranscript();
                    };
                } else {
                    this.updateUI('error', 'Speech recognition is not supported in this browser');
                }
            }

            bindEvents() {
                const micButton = document.getElementById('micButton');
                micButton.addEventListener('click', () => {
                    if (this.isRecording) {
                        this.stopRecording();
                    } else {
                        this.startRecording();
                    }
                });
            }

            async startRecording() {
                try {
                    // Get microphone access
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    
                    // Initialize MediaRecorder for audio capture
                    this.mediaRecorder = new MediaRecorder(stream);
                    this.audioChunks = [];
                    
                    this.mediaRecorder.ondataavailable = (event) => {
                        if (event.data.size > 0) {
                            this.audioChunks.push(event.data);
                        }
                    };
                    
                    this.mediaRecorder.onstop = () => {
                        stream.getTracks().forEach(track => track.stop());
                    };
                    
                    // Start recording audio
                    this.mediaRecorder.start();
                    
                    // Start speech recognition
                    if (this.recognition) {
                        this.recognition.start();
                    }
                } catch (error) {
                    console.error('Error starting recording:', error);
                    this.updateUI('error', 'Failed to access microphone');
                }
            }

            stopRecording() {
                if (this.mediaRecorder && this.mediaRecorder.state === 'recording') {
                    this.mediaRecorder.stop();
                }
                
                if (this.recognition && this.isRecording) {
                    this.recognition.stop();
                }
                
                // Process recording after a short delay to ensure all data is captured
                setTimeout(() => {
                    this.processRecording();
                }, 100);
            }

            async processRecording() {
                this.updateUI('processing', '<span class="loading"></span>Processing your recitation...');
                
                try {
                    // Get the audio data from the recognition
                    const audioBlob = await this.getAudioBlob();
                    
                    if (audioBlob) {
                        const formData = new FormData();
                        formData.append('audio', audioBlob, 'recitation.wav');
                        
                        const response = await fetch('/api/voice/recognize', {
                            method: 'POST',
                            body: formData
                        });
                        
                        const result = await response.json();
                        
                        if (result.success) {
                            this.showResult(result.result);
                        } else {
                            this.updateUI('error', result.error || 'Recognition failed');
                        }
                    } else {
                        this.updateUI('error', 'No audio data available');
                    }
                } catch (error) {
                    console.error('Error processing recording:', error);
                    this.updateUI('error', 'Failed to process recording');
                }
                
                this.updateUI('idle', 'Click the microphone to start recording');
            }

            async getAudioBlob() {
                if (this.audioChunks.length > 0) {
                    return new Blob(this.audioChunks, { type: 'audio/wav' });
                }
                return null;
            }

            updateUI(status, message) {
                const statusElement = document.getElementById('status');
                statusElement.className = `status ${status}`;
                statusElement.innerHTML = message;
                
                const micButton = document.getElementById('micButton');
                if (status === 'listening') {
                    micButton.classList.add('recording');
                } else {
                    micButton.classList.remove('recording');
                }
            }

            showTranscript() {
                document.getElementById('transcript').style.display = 'block';
            }

            hideTranscript() {
                document.getElementById('transcript').style.display = 'none';
            }

            updateTranscript(final, interim) {
                const transcriptText = document.getElementById('transcriptText');
                transcriptText.textContent = final || interim || 'Listening...';
            }

            showResult(result) {
                const resultElement = document.getElementById('result');
                const resultText = document.getElementById('resultText');
                resultText.textContent = result;
                resultElement.style.display = 'block';
            }
        }

        // Initialize the voice recognition when the page loads
        document.addEventListener('DOMContentLoaded', () => {
            new VoiceRecognition();
        });
    </script>
</body>
</html> 